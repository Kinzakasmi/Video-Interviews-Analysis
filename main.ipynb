{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install numpy  \n",
    "pip install pandas  \n",
    "pip install openpyxl  \n",
    "pip install tqdm\n",
    "pip install ffmpeg  \n",
    "pip install pydub  \n",
    "conda install -c conda-forge librosa  \n",
    "pip install -U praat-parselmouth\n",
    "pip install lime\n",
    "pip install  \n",
    "python3 -m spacy download fr_dep_news_trf  \n",
    "pip install intel-openmp  \n",
    "pip install spacy-transformers\n",
    "\n",
    "Please restart the kernel after installing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydub\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from utils import get_end_from_start, get_start_end_from_file\n",
    "from data import read_interview\n",
    "\n",
    "pydub.AudioSegment.converter = r\"C:/Users/Kinza/anaconda3/envs/pie/Library/bin/ffmpeg.exe\" #CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interviews(video_folder,startend_file) :\n",
    "    '''Loads the audios from each interview question.\n",
    "    Arguments:\n",
    "        video_folder : str. The name of the folder containing mp4 videos.\n",
    "        startend_file : str. The name of the file containing the video informations. \n",
    "            Must contain columns 'mail' and 'time'.\n",
    "    Returns a list of Interview objects\n",
    "    '''\n",
    "    filenames = tqdm(os.listdir(video_folder))\n",
    "    df_startend = get_start_end_from_file(startend_file)\n",
    "    audios = list(map(lambda f : read_interview(video_folder,df_startend,f), filenames))\n",
    "    return [item for sublist in audios for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexis.przybylak@student.isae-supaero.fr.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kinza\\anaconda3\\envs\\pie\\lib\\site-packages\\librosa\\core\\convert.py:1350: RuntimeWarning: divide by zero encountered in log10\n",
      "  + 2 * np.log10(f_sq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bonjour dernière année d'école d'ingénieur en gros c'est une école spécialisée dans le monde est le deuxième année de basket et une prépa ne sais pas à Paris je suis la sœur de l'univers et le domaine opération de paiement donc donc avec des cours et que ramadan est général l'environnement rappel à propos encore les télécommunications et le traitement d'image et pour le super héros je ne se réaliser de stage sur la propulsion électrique et le deuxième à l'érable à Toulouse sur le champ magnétique du soleil et en ce qui concerne le parcours extrascolaire en 1re année 2e année l'euro est également dans un groupe guitariste dans un groupe de musique toujours en sport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kinza\\anaconda3\\envs\\pie\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " en ce qui concerne une expérience dans un milieu international je voudrais vous parler de votre part je vends des États-Unis à l'université de Yale donc je suis parti avec un camarade de la promotion de français les universités américaines nos deux 8h et tu es espagnol et travaillons aussi avec un étudiant dans le car donc c'était un environnement international donc s'était installée sur la propulsion électrique la partie des résultats intéressants t'ai attendu toute les semaines avec de nombreuses réunions et de fonctionnement et moi\n",
      " la motivation principale réaliser mon objectif est de travailler dans le milieu en plus précisément une personne que j'ai depuis le début alors c'est toujours et tourner vers le Futur météo si on a encore demain il y a encore une certaine collaboration entre les pays est vraiment vraiment même si je suis amoureux prends jamais présent pour moi dans ce genre de métier est également un métier qui qui est rempli de laisser car il y a beaucoup de choses que tu es encore en mesure de faire donc tu n'es pas encore mal ou alors des problèmes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [03:25<1:22:22, 205.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna.gounot@student.isae-supaero.fr.mp4\n",
      " Bonjour je m'appelle Anna Bruno et je suis actuellement en dernière analyse et super-héros donc j'ai intégré après une prépa donc c'est l'école très généraliste mais rapidement je me suis embrouillé que je voulais bosser dans mon médical et du coup j'ai fait un stage ouvrier à l'hôpital dans un hôpital en première année est vraiment j'ai adoré j'ai découverte en service j'étais au service médical donc je vais aller voir tous les dispositifs qui était à disposition des médecins j'ai découvert plein de service j'ai pu aller au bloc opératoire des opérations et du coup j'ai vraiment rien te laisser de mon cœur c'est pour ça que j'ai fait aussi une année de césure j'ai fait aussi une année de césure entre ma deuxième ma 3e année l'an dernier dans un master de biomécanique à Paris donc il y a un master en partenariat avec les arts des métiers les universités de Paris de Paris Tech donc j'ai fait 6 mois de courroux j'ai dit j'ai pas mal de cellulaire la marche des personnes et après j'ai fait 5 mois de stage donc je mets la main sur ordinateur et j'ai choisi de me spécialiser dans l'étang des données de la décision qui est notion de machine learning ce genre de chose et en même temps de suivre une spécialisation en euros\n",
      " alors malheureusement j'ai pas énormément d'expérience à l'international parce que ça soit déjà au niveau du covit ça a été très compliqué pendant l'année c'est dur de partir et et et aussi le fait que quoi qu'il arrive le master que j'avais prévu de faire si tu as pas envie donc donc je suis pas vraiment parti à l'étranger dans le cadre du travail après il y a au thon ce qu'on appelle environnement international c'est vrai que j'ai pas travailler à l'étranger mais j'ai pu travailler avec des étrangers c'est vrai qu'elle super-héros en 2e année il y a beaucoup de gens étrangers qui viennent faire des échanges qui viennent en 2e année qui a intégré super-héros en 2e année super-héros en 2e année donc on est beaucoup en contact à la fois dans les dans les classes je sais que j'ai eu beaucoup de l'homme qui était étranger c'est toujours une super expérience de partager un peu nos différents points de vue en culture et de voir comment chacun appréhender le travail en fait et de travailler ensemble c'est toujours très enrichissant et et aussi on lui je sais qu'il y a une semaine où on a beaucoup de travail on en a plus salle où on a beaucoup travaillé entre étudiants un peu de tous les tous les horizons j'ai pu travailler avec des personnes qui venaient du Brésil kiné d'Espagne qui venait d'Italie kiné de kiné de culture\n",
      " très bien la communication alors je pense que je voulais les comprimés ce qui motive vraiment c'est le domaine du médical parce que c'est la seule que j'ai accès mon cursus et ses lettres donc j'ai envie de continuer de travailler plus tard et pourquoi est-ce que c'est domaine motif particules particulièrement en fait c'est parce que ben au travers de mes différentes expériences mais tu fais mon stage je me suis rendu compte que bon ben on a tous besoin d'aimer son quotidien que ce soit pour soigner nos petits bobos mais en fait les médecins ont aussi besoin de nous quand je dis dans ce cas-là je parle plus parce que pour créer de nouveaux systèmes de m de nouveaux dispositifs médicaux qui vont faciliter diagnostic faciliter le traitement de pathologie et ça peut être aussi ça peut être des pathologies qui peuvent être des problèmes mais ça peut aussi être améliorer le quotidien de deux personnes en posant des prothèses ce genre de chose donc vraiment le médecin a besoin des ingénieurs pour apporter de nouvelles innovations et nouvelles technologies et je m'en suis vraiment rendu compte quand j'ai fait mon stage du coup elle dit PSG c'est l'an dernier parce que j'ai pu travailler avec un chirurgien orthopédiste et lui il était en thèse et c'était vraiment très intéressant de voir que moi j'étais vraiment très fort ben moi j'étais vraiment très focaliser sur les résultats les chiffres la précision ce genre de chose et puis un moment il arrivait à mettre en perspective tout ça et à me dire peut-être que la précision c'est peut-être pas la meilleure mais en attendant tu as réussi à faire quelque chose qui est super tu as réussi à calculer la distance entre l'hôtel était là et c'est très important pour le mettre dans de savoir pour diagnostiquer des pathologies tu as réussi à faire quelque chose est vraiment j'avais l'impression en fait que ce que je faisais c'était génial et moi je savais que c'était génial en fait du coup il y avait cette communication est sûr que c'est très important fait d'avoir leur leur vision des choses pour savoir exactement au fait finalement on est au service et n'est pas pour pour les ce n'est pas pour pour les aider et donc d'avoir leur maison et de communiquer avec eux ça nous permet de voir leurs besoins et de mieux y répondre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [06:22<1:12:15, 188.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basile.rochut@student.isae-supaero.fr.mp4\n",
      " Bonjour je m'appelle Basile refus je suis étudiant en dernière année de cycle ingénieur Hallyday super-héros à Toulouse\n",
      " je pense que dans ces valeurs celle qui me correspond le plus serein parents et finalement je suis rendu compte lorsque je devais malade j'ai 7 équipes que plus important c'était que tout le monde arrive à se sentir à l'aise dans les tâches qui lui était confiée et que bah tout seul on peut pas tout faire mais ça c'était peut-être un défaut que j'avais auparavant et je me suis rendu compte de l'importance du travail d'équipe et je m'en rends compte également rendu compte également grâce à un message sur mon stage de césure j'ai travaillé sur le Vendée Globe j'étais avec mon tuteur et un autre employé nous travaillons sur le développement de l'automatisation et il va tout seul et il va tout seul impossible réaliser la tâche c'est le travail d'équipe une émulation qui était très importante\n",
      " par une fois où j'ai dû prendre une cette que j'ai en tête ce serait départ et en leur donnant toutes les données récupérer la vie je me suis rendu compte que les erreurs qu'on trouve dans mon fils et développement non pas demandé des résultats de la qui me faisait une erreur dans leur pays et finalement c'est plutôt bien déroulé plus que je les ai aidés à résoudre ce problème là et ça a été notifié par l'entreprise à mon tuteur qui était très ravi que\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [07:40<50:38, 138.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boudabousarah@gmail.com.mp4\n",
      " en relations internationales\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [07:42<56:33, 154.23s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m video_folder \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39mvideos/\u001B[39m\u001B[39m'\u001B[39m\n\u001B[0;32m      2\u001B[0m df_name \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39mnotes_entretiens_all.xlsx\u001B[39m\u001B[39m'\u001B[39m\n\u001B[1;32m----> 4\u001B[0m interviews \u001B[39m=\u001B[39m load_interviews(video_folder,df_name)\n",
      "\u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\main.ipynb Cell 4'\u001B[0m in \u001B[0;36mload_interviews\u001B[1;34m(video_folder, startend_file)\u001B[0m\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=11'>12</a>\u001B[0m filenames \u001B[39m=\u001B[39m tqdm(os\u001B[39m.\u001B[39mlistdir(video_folder))\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=12'>13</a>\u001B[0m df_startend \u001B[39m=\u001B[39m get_start_end_from_file(startend_file)\n\u001B[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=13'>14</a>\u001B[0m audios \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39;49m(\u001B[39mmap\u001B[39;49m(\u001B[39mlambda\u001B[39;49;00m f : read_interview(video_folder,df_startend,f), filenames))\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=14'>15</a>\u001B[0m \u001B[39mreturn\u001B[39;00m [item \u001B[39mfor\u001B[39;00m sublist \u001B[39min\u001B[39;00m audios \u001B[39mfor\u001B[39;00m item \u001B[39min\u001B[39;00m sublist]\n",
      "\u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\main.ipynb Cell 4'\u001B[0m in \u001B[0;36mload_interviews.<locals>.<lambda>\u001B[1;34m(f)\u001B[0m\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=11'>12</a>\u001B[0m filenames \u001B[39m=\u001B[39m tqdm(os\u001B[39m.\u001B[39mlistdir(video_folder))\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=12'>13</a>\u001B[0m df_startend \u001B[39m=\u001B[39m get_start_end_from_file(startend_file)\n\u001B[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=13'>14</a>\u001B[0m audios \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39m(\u001B[39mmap\u001B[39m(\u001B[39mlambda\u001B[39;00m f : read_interview(video_folder,df_startend,f), filenames))\n\u001B[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000003?line=14'>15</a>\u001B[0m \u001B[39mreturn\u001B[39;00m [item \u001B[39mfor\u001B[39;00m sublist \u001B[39min\u001B[39;00m audios \u001B[39mfor\u001B[39;00m item \u001B[39min\u001B[39;00m sublist]\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:42\u001B[0m, in \u001B[0;36mread_interview\u001B[1;34m(video_folder, df_startend, filename, min_silence_len, silence_thresh, keep_silence, n_fft, hop_length)\u001B[0m\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=39'>40</a>\u001B[0m audios \u001B[39m=\u001B[39m split_questions(video_folder,df_startend,filename)\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=40'>41</a>\u001B[0m \u001B[39m#Preprocessing\u001B[39;00m\n\u001B[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=41'>42</a>\u001B[0m interviews \u001B[39m=\u001B[39m [Interview(audio, filename\u001B[39m.\u001B[39msplit(\u001B[39m'\u001B[39m\u001B[39m.mp4\u001B[39m\u001B[39m'\u001B[39m,\u001B[39m2\u001B[39m)[\u001B[39m0\u001B[39m], i\u001B[39m+\u001B[39m\u001B[39m1\u001B[39m,\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=42'>43</a>\u001B[0m                         min_silence_len\u001B[39m=\u001B[39mmin_silence_len,silence_thresh\u001B[39m=\u001B[39msilence_thresh,keep_silence\u001B[39m=\u001B[39mkeep_silence,\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=43'>44</a>\u001B[0m                         n_fft\u001B[39m=\u001B[39mn_fft,hop_length\u001B[39m=\u001B[39mhop_length          \n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=44'>45</a>\u001B[0m                         ) \u001B[39mfor\u001B[39;00m (i,audio) \u001B[39min\u001B[39;00m \u001B[39menumerate\u001B[39m(audios)]\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=45'>46</a>\u001B[0m \u001B[39mreturn\u001B[39;00m interviews\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:42\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=39'>40</a>\u001B[0m audios \u001B[39m=\u001B[39m split_questions(video_folder,df_startend,filename)\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=40'>41</a>\u001B[0m \u001B[39m#Preprocessing\u001B[39;00m\n\u001B[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=41'>42</a>\u001B[0m interviews \u001B[39m=\u001B[39m [Interview(audio, filename\u001B[39m.\u001B[39;49msplit(\u001B[39m'\u001B[39;49m\u001B[39m.mp4\u001B[39;49m\u001B[39m'\u001B[39;49m,\u001B[39m2\u001B[39;49m)[\u001B[39m0\u001B[39;49m], i\u001B[39m+\u001B[39;49m\u001B[39m1\u001B[39;49m,\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=42'>43</a>\u001B[0m                         min_silence_len\u001B[39m=\u001B[39;49mmin_silence_len,silence_thresh\u001B[39m=\u001B[39;49msilence_thresh,keep_silence\u001B[39m=\u001B[39;49mkeep_silence,\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=43'>44</a>\u001B[0m                         n_fft\u001B[39m=\u001B[39;49mn_fft,hop_length\u001B[39m=\u001B[39;49mhop_length          \n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=44'>45</a>\u001B[0m                         ) \u001B[39mfor\u001B[39;00m (i,audio) \u001B[39min\u001B[39;00m \u001B[39menumerate\u001B[39m(audios)]\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=45'>46</a>\u001B[0m \u001B[39mreturn\u001B[39;00m interviews\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:12\u001B[0m, in \u001B[0;36mInterview.__init__\u001B[1;34m(self, audio, email, question, min_silence_len, silence_thresh, keep_silence, n_fft, hop_length)\u001B[0m\n\u001B[0;32m      <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=8'>9</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mAudio \u001B[39m=\u001B[39m Audio(audio,email,question,min_silence_len,silence_thresh,keep_silence,n_fft,hop_length)\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=9'>10</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mAudio\u001B[39m.\u001B[39mpreprocessing()\n\u001B[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=11'>12</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mLexic \u001B[39m=\u001B[39m Lexic(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mAudio\u001B[39m.\u001B[39;49maudio,\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mAudio\u001B[39m.\u001B[39;49mprosodic_features[\u001B[39m'\u001B[39;49m\u001B[39moriginaldur\u001B[39;49m\u001B[39m'\u001B[39;49m])\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=13'>14</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mLexic\u001B[39m.\u001B[39mpreprocessing()\n\u001B[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=15'>16</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mfeatures \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mset_features()\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:160\u001B[0m, in \u001B[0;36mLexic.__init__\u001B[1;34m(self, audio, time)\u001B[0m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=156'>157</a>\u001B[0m \u001B[39m## Assembling all usable data in a pandas dataframe ##\u001B[39;00m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=157'>158</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mlexical_features \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39mDataFrame()  \u001B[39m##Done      Dataframe of all lexical features\u001B[39;00m\n\u001B[1;32m--> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=159'>160</a>\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mset_ALL(time)\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:380\u001B[0m, in \u001B[0;36mLexic.set_ALL\u001B[1;34m(self, time)\u001B[0m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=377'>378</a>\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mset_ALL\u001B[39m(\u001B[39mself\u001B[39m, time):\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=378'>379</a>\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mset_words()\n\u001B[1;32m--> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=379'>380</a>\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mset_vec()\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=380'>381</a>\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mset_spacy_feats()\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=381'>382</a>\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mset_dictionary()\n",
      "File \u001B[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:261\u001B[0m, in \u001B[0;36mLexic.set_vec\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=255'>256</a>\u001B[0m \u001B[39m'''\u001B[39;00m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=256'>257</a>\u001B[0m \u001B[39m    Set vectorized words list as a private argument\u001B[39;00m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=257'>258</a>\u001B[0m \u001B[39m'''\u001B[39;00m\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=259'>260</a>\u001B[0m countvect \u001B[39m=\u001B[39m CountVectorizer(tokenizer\u001B[39m=\u001B[39mFrenchStemTokenizer(remove_non_words\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m))\n\u001B[1;32m--> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=260'>261</a>\u001B[0m text_fts \u001B[39m=\u001B[39m countvect\u001B[39m.\u001B[39;49mfit_transform([\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_speech])\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=262'>263</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_vec \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39m(countvect\u001B[39m.\u001B[39mget_feature_names_out())\n\u001B[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=263'>264</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnb_vec \u001B[39m=\u001B[39m \u001B[39mlen\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_vec)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1321'>1322</a>\u001B[0m             warnings\u001B[39m.\u001B[39mwarn(\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1322'>1323</a>\u001B[0m                 \u001B[39m\"\u001B[39m\u001B[39mUpper case characters found in\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1323'>1324</a>\u001B[0m                 \u001B[39m\"\u001B[39m\u001B[39m vocabulary while \u001B[39m\u001B[39m'\u001B[39m\u001B[39mlowercase\u001B[39m\u001B[39m'\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1324'>1325</a>\u001B[0m                 \u001B[39m\"\u001B[39m\u001B[39m is True. These entries will not\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1325'>1326</a>\u001B[0m                 \u001B[39m\"\u001B[39m\u001B[39m be matched with any documents\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1326'>1327</a>\u001B[0m             )\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1327'>1328</a>\u001B[0m             \u001B[39mbreak\u001B[39;00m\n\u001B[1;32m-> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1329'>1330</a>\u001B[0m vocabulary, X \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_count_vocab(raw_documents, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mfixed_vocabulary_)\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1331'>1332</a>\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbinary:\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1332'>1333</a>\u001B[0m     X\u001B[39m.\u001B[39mdata\u001B[39m.\u001B[39mfill(\u001B[39m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1220\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1217'>1218</a>\u001B[0m     vocabulary \u001B[39m=\u001B[39m \u001B[39mdict\u001B[39m(vocabulary)\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1218'>1219</a>\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m vocabulary:\n\u001B[1;32m-> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1219'>1220</a>\u001B[0m         \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1220'>1221</a>\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mempty vocabulary; perhaps the documents only contain stop words\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1221'>1222</a>\u001B[0m         )\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1223'>1224</a>\u001B[0m \u001B[39mif\u001B[39;00m indptr[\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m] \u001B[39m>\u001B[39m np\u001B[39m.\u001B[39miinfo(np\u001B[39m.\u001B[39mint32)\u001B[39m.\u001B[39mmax:  \u001B[39m# = 2**31 - 1\u001B[39;00m\n\u001B[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1224'>1225</a>\u001B[0m     \u001B[39mif\u001B[39;00m _IS_32BIT:\n",
      "\u001B[1;31mValueError\u001B[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "video_folder = 'videos/'\n",
    "df_name = 'notes_entretiens_all.xlsx'\n",
    "\n",
    "interviews = load_interviews(video_folder,df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aid',\n",
       " 'ais',\n",
       " 'anné',\n",
       " 'appel',\n",
       " 'arriv',\n",
       " 'auparav',\n",
       " 'automatis',\n",
       " 'autr',\n",
       " 'bah',\n",
       " 'basil',\n",
       " 'bien',\n",
       " 'bonjour',\n",
       " 'cel',\n",
       " 'cet',\n",
       " 'compt',\n",
       " 'confi',\n",
       " 'correspond',\n",
       " 'cycl',\n",
       " 'césur',\n",
       " 'demand',\n",
       " 'derni',\n",
       " 'dev',\n",
       " 'don',\n",
       " 'défaut',\n",
       " 'départ',\n",
       " 'déroul',\n",
       " 'développ',\n",
       " 'dû',\n",
       " 'emploi',\n",
       " 'entrepris',\n",
       " 'erreur',\n",
       " 'fair',\n",
       " 'fais',\n",
       " 'fil',\n",
       " 'final',\n",
       " 'fois',\n",
       " 'glob',\n",
       " 'grâc',\n",
       " 'hallyday',\n",
       " 'héros',\n",
       " 'import',\n",
       " 'impossibl',\n",
       " 'ingénieur',\n",
       " 'lorsqu',\n",
       " 'là',\n",
       " 'malad',\n",
       " 'messag',\n",
       " 'mond',\n",
       " 'non',\n",
       " 'notifi',\n",
       " 'où',\n",
       " 'parent',\n",
       " 'pay',\n",
       " 'pens',\n",
       " 'peut',\n",
       " 'plus',\n",
       " 'plutôt',\n",
       " 'prendr',\n",
       " 'problem',\n",
       " 'rav',\n",
       " 'refus',\n",
       " 'rend',\n",
       " 'rendu',\n",
       " 'réalis',\n",
       " 'récuper',\n",
       " 'résoudr',\n",
       " 'résultat',\n",
       " 'sent',\n",
       " 'serein',\n",
       " 'seul',\n",
       " 'stag',\n",
       " 'sup',\n",
       " 'toulous',\n",
       " 'tout',\n",
       " 'travail',\n",
       " 'travaill',\n",
       " 'travaillon',\n",
       " 'tres',\n",
       " 'trouv',\n",
       " 'tuteur',\n",
       " 'tâch',\n",
       " 'têt',\n",
       " 'va',\n",
       " 'valeur',\n",
       " 'vend',\n",
       " 'vi',\n",
       " 'ça',\n",
       " 'égal',\n",
       " 'émul',\n",
       " 'équip',\n",
       " 'étudi',\n",
       " 'être']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "\n",
    "class FrenchStemTokenizer(object):\n",
    "\n",
    "    def __init__(self, remove_non_words=False):\n",
    "        self.st = FrenchStemmer()\n",
    "        self.stopwords = set(stopwords.words('french'))\n",
    "        self.words = set(words.words())\n",
    "        self.remove_non_words = remove_non_words\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        # tokenize words and punctuation\n",
    "        word_list = wordpunct_tokenize(doc)\n",
    "        # remove stopwords\n",
    "        word_list = [word for word in word_list if word not in self.stopwords]\n",
    "        # remove non words\n",
    "        if (self.remove_non_words):\n",
    "            word_list = [word for word in word_list if word in self.words]\n",
    "        # remove 1-character words\n",
    "        word_list = [word for word in word_list if len(word) > 1]\n",
    "        # remove non alpha\n",
    "        word_list = [word for word in word_list if word.isalpha()]\n",
    "        return [self.st.stem(t) for t in word_list]\n",
    "\n",
    "_speech = \"Bonjour je m'appelle Basile refus je suis étudiant en dernière année de cycle ingénieur Hallyday super-héros à Toulouse je pense que dans ces valeurs celle qui me correspond le plus serein parents et finalement je suis rendu compte lorsque je devais malade j'ai 7 équipes que plus important c'était que tout le monde arrive à se sentir à l'aise dans les tâches qui lui était confiée et que bah tout seul on peut pas tout faire mais ça c'était peut-être un défaut que j'avais auparavant et je me suis rendu compte de l'importance du travail d'équipe et je m'en rends compte également rendu compte également grâce à un message sur mon stage de césure j'ai travaillé sur le Vendée Globe j'étais avec mon tuteur et un autre employé nous travaillons sur le développement de l'automatisation et il va tout seul et il va tout seul impossible réaliser la tâche c'est le travail d'équipe une émulation qui était très importante par une fois où j'ai dû prendre une cette que j'ai en tête ce serait départ et en leur donnant toutes les données récupérer la vie je me suis rendu compte que les erreurs qu'on trouve dans mon fils et développement non pas demandé des résultats de la qui me faisait une erreur dans leur pays et finalement c'est plutôt bien déroulé plus que je les ai aidés à résoudre ce problème là et ça a été notifié par l'entreprise à mon tuteur qui était très ravi que\"\n",
    "\n",
    "countvect = CountVectorizer()\n",
    "text_fts = countvect.fit_transform([_speech])\n",
    "\n",
    "count_array = text_fts.toarray()\n",
    "\n",
    "_words = list(countvect.get_feature_names_out())\n",
    "word_count = count_array.sum()\n",
    "\n",
    "countvect = CountVectorizer(tokenizer=FrenchStemTokenizer(remove_non_words=False))\n",
    "text_fts = countvect.fit_transform([_speech])\n",
    "\n",
    "_vec = list(countvect.get_feature_names_out())\n",
    "\n",
    "_vec"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22481484a5f7e79f314e40293bb4bf1039ec3aa5f1615d995a7f4d567969c466"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}