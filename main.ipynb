{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install numpy  \n",
    "pip install pandas  \n",
    "pip install openpyxl  \n",
    "pip install tqdm\n",
    "pip install ffmpeg  \n",
    "pip install pydub  \n",
    "conda install -c conda-forge librosa  \n",
    "pip install -U praat-parselmouth\n",
    "pip install lime\n",
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydub\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "pydub.AudioSegment.converter = r\"C:/Users/Kinza/anaconda3/envs/pie/Library/bin/ffmpeg.exe\" #CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_end_from_start, get_start_end_from_file\n",
    "from data import read_interview\n",
    "\n",
    "def load_interviews(video_folder,startend_file) :\n",
    "    '''Loads the audios from each interview question.\n",
    "    Arguments:\n",
    "        video_folder : str. The name of the folder containing mp4 videos.\n",
    "        startend_file : str. The name of the file containing the video informations. \n",
    "            Must contain columns 'mail' and 'time'.\n",
    "    Returns a list of Interview objects\n",
    "    '''\n",
    "    filenames = tqdm(os.listdir(video_folder))\n",
    "    df_startend = get_start_end_from_file(startend_file)\n",
    "    audios = list(map(lambda f : read_interview(video_folder,df_startend,f), filenames))\n",
    "    return [item for sublist in audios for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexis.przybylak@student.isae-supaero.fr.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kinza\\anaconda3\\envs\\pie\\lib\\site-packages\\librosa\\core\\convert.py:1350: RuntimeWarning: divide by zero encountered in log10\n",
      "  + 2 * np.log10(f_sq)\n",
      "  0%|          | 0/25 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioSegment' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\main.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000005?line=0'>1</a>\u001b[0m video_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000005?line=1'>2</a>\u001b[0m df_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnotes_entretiens_all.xlsx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000005?line=3'>4</a>\u001b[0m interviews \u001b[39m=\u001b[39m load_interviews(video_folder,df_name)\n",
      "\u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\main.ipynb Cell 3'\u001b[0m in \u001b[0;36mload_interviews\u001b[1;34m(video_folder, startend_file)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=11'>12</a>\u001b[0m filenames \u001b[39m=\u001b[39m tqdm(os\u001b[39m.\u001b[39mlistdir(video_folder))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=12'>13</a>\u001b[0m df_startend \u001b[39m=\u001b[39m get_start_end_from_file(startend_file)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=13'>14</a>\u001b[0m audios \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m f : read_interview(video_folder,df_startend,f), filenames))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m audios \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist]\n",
      "\u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\main.ipynb Cell 3'\u001b[0m in \u001b[0;36mload_interviews.<locals>.<lambda>\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=11'>12</a>\u001b[0m filenames \u001b[39m=\u001b[39m tqdm(os\u001b[39m.\u001b[39mlistdir(video_folder))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=12'>13</a>\u001b[0m df_startend \u001b[39m=\u001b[39m get_start_end_from_file(startend_file)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=13'>14</a>\u001b[0m audios \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m f : read_interview(video_folder,df_startend,f), filenames))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/main.ipynb#ch0000001?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m audios \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist]\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:39\u001b[0m, in \u001b[0;36mread_interview\u001b[1;34m(video_folder, df_startend, filename)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=36'>37</a>\u001b[0m audios \u001b[39m=\u001b[39m split_questions(video_folder,df_startend,filename)\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=37'>38</a>\u001b[0m \u001b[39m#Preprocessing\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=38'>39</a>\u001b[0m interviews \u001b[39m=\u001b[39m [Interview(audio, filename\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.mp4\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m2\u001b[39m)[\u001b[39m0\u001b[39m], i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (i,audio) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(audios)]\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m interviews\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=36'>37</a>\u001b[0m audios \u001b[39m=\u001b[39m split_questions(video_folder,df_startend,filename)\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=37'>38</a>\u001b[0m \u001b[39m#Preprocessing\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=38'>39</a>\u001b[0m interviews \u001b[39m=\u001b[39m [Interview(audio, filename\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m2\u001b[39;49m)[\u001b[39m0\u001b[39;49m], i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m (i,audio) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(audios)]\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m interviews\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\data.py:11\u001b[0m, in \u001b[0;36mInterview.__init__\u001b[1;34m(self, audio, email, question, min_silence_len, silence_thresh, keep_silence, n_fft, hop_length)\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAudio \u001b[39m=\u001b[39m Audio(audio,email,question,min_silence_len,silence_thresh,keep_silence,n_fft,hop_length)\n\u001b[0;32m      <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAudio\u001b[39m.\u001b[39mpreprocessing()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLexic \u001b[39m=\u001b[39m Lexic(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mAudio\u001b[39m.\u001b[39;49maudio,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mAudio\u001b[39m.\u001b[39;49mprosodic_features[\u001b[39m'\u001b[39;49m\u001b[39moriginaldur\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLexic\u001b[39m.\u001b[39mpreprocessing()\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/data.py?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_features()\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:77\u001b[0m, in \u001b[0;36mLexic.__init__\u001b[1;34m(self, audio, time)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=73'>74</a>\u001b[0m \u001b[39m## Assembling all usable data in a pandas dataframe ##\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlexical_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()  \u001b[39m##Done      Dataframe of all lexical features\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_ALL(time)\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:296\u001b[0m, in \u001b[0;36mLexic.set_ALL\u001b[1;34m(self, time)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=294'>295</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_ALL\u001b[39m(\u001b[39mself\u001b[39m, time):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=295'>296</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_words()\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=296'>297</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_vec()\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=297'>298</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_spacy_feats()\n",
      "File \u001b[1;32mc:\\Users\\Kinza\\Documents\\GitHub\\Video-interviews-analysis\\speech_feats_extract.py:166\u001b[0m, in \u001b[0;36mLexic.set_words\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=159'>160</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=160'>161</a>\u001b[0m \u001b[39m    Set the private variable words as a list of all words and word count as the sum of the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=161'>162</a>\u001b[0m \u001b[39m    number of words used times their occurence.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=162'>163</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=164'>165</a>\u001b[0m countvect \u001b[39m=\u001b[39m CountVectorizer()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=165'>166</a>\u001b[0m text_fts \u001b[39m=\u001b[39m countvect\u001b[39m.\u001b[39;49mfit_transform([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_speech])\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=166'>167</a>\u001b[0m count_array \u001b[39m=\u001b[39m text_fts\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m    <a href='file:///c%3A/Users/Kinza/Documents/GitHub/Video-interviews-analysis/speech_feats_extract.py?line=168'>169</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_words \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(countvect\u001b[39m.\u001b[39mget_feature_names_out())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1321'>1322</a>\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1322'>1323</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1323'>1324</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1324'>1325</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1325'>1326</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1326'>1327</a>\u001b[0m             )\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1327'>1328</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1329'>1330</a>\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1331'>1332</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1332'>1333</a>\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1198'>1199</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1199'>1200</a>\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1200'>1201</a>\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1201'>1202</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=1202'>1203</a>\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=110'>111</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=111'>112</a>\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=112'>113</a>\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=113'>114</a>\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=114'>115</a>\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pie\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:71\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=51'>52</a>\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=52'>53</a>\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=53'>54</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=67'>68</a>\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=68'>69</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=70'>71</a>\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=71'>72</a>\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/pie/lib/site-packages/sklearn/feature_extraction/text.py?line=72'>73</a>\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AudioSegment' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "video_folder = 'videos/'\n",
    "df_name = 'notes_entretiens_all.xlsx'\n",
    "\n",
    "interviews = load_interviews(video_folder,df_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22481484a5f7e79f314e40293bb4bf1039ec3aa5f1615d995a7f4d567969c466"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
